<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>HTML5音频可视化频谱跳动代码</title>
  <style>
    * {
      margin: 0;
      padding: 0;
    }

    #canvas {
        position: absolute;  
        top:0;
        left: 0px; 
        width:100%;
        margin: auto;
        /*background: linear-gradient(135deg, rgb(206, 68, 201) 0%, rgb(255, 255, 255) 100%);*/ 
        z-index:-1;
    }
    #myaudio{  
        position: absolute;  
        top:0;
        left: 0px; 
        width:100%;
        margin: auto;
        height: auto;  
        z-index:-1;
    }

  </style>
</head>

<body>
    <input type="file" onchange="selectFile(this)" id="file"/>
    <video id="myaudio" crossOrigin="anonymous">
        <source id="src" src="">
    </video>
    <canvas id="canvas"></canvas>
  <script>
    var flag = true;
    var oAudio = document.getElementById('myaudio');
    var canvas = document.getElementById("canvas");
    var oCtx, analyser, audioSrc, ctx, oW, oH, color1, voiceHeight;
    // 宽度
    var step = 2;
    var base = -15;
    function init() {
        if (flag) {
            // 创建音频上下文对象
            oCtx = new AudioContext();
            // console.log(oCtx);
            // 创建媒体源,除了audio本身可以获取，也可以通过oCtx对象提供的api进行媒体源操作
            audioSrc = oCtx.createMediaElementSource(oAudio);
            flag = false;
            // 创建分析机
            analyser = oCtx.createAnalyser();
            // 媒体源与分析机连接
            audioSrc.connect(analyser);
            // 输出的目标：将分析机分析出来的处理结果与目标点（耳机/扬声器）连接
            analyser.connect(oCtx.destination);

            // 效果（实现的具体方法）
            // 绘制音频图的条数(fftSize)
            /*
            根据分析音频的数据去获取音频频次界定音频图的高度
            放在与音频频次等长的8位无符号字节数组
            Uint8Array:初始化默认值为1024
             */
            // 利用cancas渐变进行音频绘制
            ctx = canvas.getContext('2d');
            
            oAudio.width = window.innerWidth;
            canvas.width = oAudio.width;
            canvas.height = oAudio.width*9/16;
            oW = canvas.width;
            oH = canvas.height;
            color1 = '#9e0099';
            ctx.strokeStyle='white';
            ctx.fillStyle = color1; // 绘制向上的线条
            ctx.globalAlpha = 0.5;
            // 缓冲区:进行数据的缓冲处理，转换成二进制数据
            voiceHeight = new Uint8Array(analyser.frequencyBinCount);
        }
        /** 线 */
        
        function draw1() {
            // 将当前的频率数据复制到传入的无符号字节数组中，做到实时连接
            analyser.getByteFrequencyData(voiceHeight);
            //console.log(voiceHeight.length);
            // 自定义获取数组里边数据的频步
            ctx.clearRect(0, 0, oW, oH);
            ctx.beginPath();
            ctx.moveTo(0,oH);
            var max = 0;
            var i = 0;
            for (; i < voiceHeight.length&&i * step<oW; i++) {
                ctx.lineTo(i * step, oH - voiceHeight[i] - base);
                max = max + voiceHeight[i] + base;
            }
            max = max/i;
            ctx.lineTo(oW, oH);
            ctx.closePath();
            ctx.fill();
            ctx.stroke();
            
            ctx.beginPath();
            ctx.moveTo(0, oH - max);
            ctx.lineTo(oW, oH - max);
            ctx.closePath();
            ctx.stroke();
            
            window.requestAnimationFrame(draw1);
        }
        /** 柱 */
        function draw2() {
            // 将当前的频率数据复制到传入的无符号字节数组中，做到实时连接
            analyser.getByteFrequencyData(voiceHeight);
            //console.log(voiceHeight.length);
            // 自定义获取数组里边数据的频步
            ctx.clearRect(0, 0, oW, oH);
            var i = 0;
            for (; i < voiceHeight.length&&i * step<oW; i++) {
                // 柱状
                ctx.fillRect(i * step, oH/2, step-1, -voiceHeight[i]-base);
                ctx.fillRect(i * step, oH/2, step-1, voiceHeight[i]+base);
            }
            
            window.requestAnimationFrame(draw2);
        }
        draw1();
        window.onresize = function() {
            oAudio.width = window.innerWidth;
            canvas.width = oAudio.width;
            canvas.height = oAudio.width*9/16;
            oW = canvas.width;
            oH = canvas.height;
            oAudio.width = oW;
            oAudio.height = oH;
            ctx.strokeStyle='white';
            ctx.fillStyle = color1; // 绘制向上的线条
            ctx.globalAlpha = 0.5;
            window.scrollTo(0, 1080);
            
        };
        oAudio.play();
        file["style"]='display:none;';
        window.scrollTo(0, 1080);

        /*
        analyserNode 提供了时时频率以及时间域的分析信息
        允许你获取实时的数据，并进行音频可视化
        analyserNode接口的fftSize属性
        fftSize:无符号长整型值，用于确定频域的FFT(快速傅里叶变换)
        ffiSize属性值是从32位到32768范围内的2的非零幂,默认值是2048
         */
    }
    function selectFile(t) {
        var file = t.files[0];
        var url = URL.createObjectURL(file);
        if (file) {
            document.getElementById('myaudio').src = url;
            init();
        }
    }
    canvas.onclick = function () {
        if (oAudio.paused) {
            oAudio.play();
        } else {
            oAudio.pause();
        }
    }

  </script>
</body>

</html>
